# 人工智能编程实践大作业
## 分布外泛化问题概述
深度神经网络通常采用独立同分布的假设进行训练，即假设测试数据分布与训练数据分布相似。然
而，当用于实际任务时，这一假设并不成立，导致其性能显著下降。例如，对于猫狗二分类问题，如果
训练集中所有狗都在草地上，所有的猫都在沙发上，而测试集反之，那么模型在没有测试集信息的情况
下，很有可能会把沙发和猫联系在一起，在测试时将会把在沙发上的狗误认为是猫。理想的人工智能系
统应尽可能在分布外（Out-of-Distribution）的情况下有较强的泛化能力。本文以彩色数字识别数据集
为例，对常见的OoD算法进行探索、总结，并通过引入边缘信息提取等方式，对其中IRM、RSC等算
法进行改进。

在分布外（Out-of-Distribution, OoD）泛化问题中，要区分两种偏移的形式，一种是**多样
性偏移**，另一种是**相关性偏移**。多样性偏移主要源于测试集中出现了训练集中概率极低的全新特征
或风格。相关性偏移则通常是由于一个非因果的、虚假的特征与标签在训练环境中高度相关，而这
种相关性在测试环境中减弱甚至反转，造成泛化的困难。比如经典的狗在草地上、猫在沙发上的问
题。
本次实验主要关注多样性偏移的情况，基本的数据集1为 Colored MNIST 的变体：在三种训练
环境中，数据分别为红色数字黑色背景、绿色数字黑色背景、白色数字黑色背景；在测试阶段，数
据分别为黄色数字白色背景、蓝色数字白色背景。
### 实验过程
- 在初级阶段，我们先构建了一个LeNet模型，探索此模型在数据集1上的表现；
- 在中级阶段，我们尝试对训练集进行增广，得到数据集2，并在此基础上探索LeNet的表现，给出可视化；
- 在高级阶段，我们保留原有的训练集，对测试集进行增广，得到数据集3，并在LeNet架构的基础上加入
了IRM，RSC等常见的OoD算法，基于它们的实际表现做出分析和改进，并给出一些提高泛化性能
的经验性方法。
